{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00462e9-a96d-4f8d-af5b-5638a63522bf",
   "metadata": {},
   "source": [
    "<h1>Random Forest Classifiers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1118717-0322-487c-89c0-1c777fea6b01",
   "metadata": {},
   "source": [
    "<h2>What are Random Forests?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deda6e1-7005-4937-8ff1-6cef72d60e4e",
   "metadata": {},
   "source": [
    "<i>\"A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\"</i>\n",
    "- <a href = https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html>sci-kit learn documentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a699908-3608-4295-be3d-a48f8f05c724",
   "metadata": {},
   "source": [
    "In simpler terms, <b>Random Forest Classifiers</b> directly build upon <b>Decision Trees</b> by using multiple trees to form a 'forest', hence the name. To prevent <i>overfitting</i>, which <b>Decision Trees</b> are prone to do, the <b>Random Forest</b> consists of independently working trees which only factor in a subsection of the training data. The output of the forest is then voted on by its trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2c9f3-5cef-42a8-beb2-16ea933ce537",
   "metadata": {},
   "source": [
    "<img src = https://media.geeksforgeeks.org/wp-content/uploads/20240215110349/randomforest.webp alt = 'Visualisation of a Random Forest'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7261b-f8a6-4705-a379-4122445f0504",
   "metadata": {},
   "source": [
    "By randomly splitting the <b><font color = 'green'>Training Set</font></b> into smaller subsections of <b><font color = 'blue'>Training Data</font></b>, the resulting <b><font color = 'orange'>Decision Trees</font></b> are built upon different sections of the set. Additionally, the forest introduces randomness at the different nodes of the trees by choosing a subset of features that should be accounted for at this node. This ultimately leads to a diverse set of <b><font color = 'orange'>Decision Trees</font></b>, preventing them from potentially running into the same issues. For the final result, the trees <b><font color = 'red'>vote</font></b> on their respective result: Whichever result receives the most votes is chosen as the final <b><font color = 'green'>prediction</font></b> of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63ea12-c57d-4f10-8569-c8dd15866ac5",
   "metadata": {},
   "source": [
    "<h2>Pros and Cons of Random Forest Classifiers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46fa2b-d54a-4fbd-8cd7-96bfe8bcfd55",
   "metadata": {},
   "source": [
    "<h3>Pros:</h3>\n",
    "<ol>\n",
    "    <li>Since the final prediction is chosen by <b>Decision Trees</b> that processed different parts of the data, the final result is generally highly accurate. Since misrepresentation of the data and overfitting will only affect a few of the trees at most, the final result is much more reliable</li>\n",
    "    <li>Robust to noise in the data. As the individual trees only ever see part of the data, noise as well as missing data and outliers do not affect all of the trees.</li>\n",
    "    <li><b>Random Forests</b> can handle both numerical as well as categorical data. However, Sk-learn's algorithm only supports numerical data.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184b585-a84d-4eac-8dc2-7a4afeb3207b",
   "metadata": {},
   "source": [
    "<h3>Cons:</h3>\n",
    "<ol>\n",
    "    <li><b>Random Forests</b> are highly complex, requiring higher computational power and memory, especially on larger datasets. Additionally, they take a lot longer than other algorithms to make a prediction.</li>\n",
    "    <li>In line with their computational complexity, the forest becomes very difficult to interpret due to the sheer amount of trees.</li>\n",
    "    <li>Despite the measures to prevent it, overfitting may still occur.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdbab8-e560-4656-a2bf-80e39e32ad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
